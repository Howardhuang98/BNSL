{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lingam\n",
    "from dlbn.data_generator import DataGenerator\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 生成数据\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.   1.9 -0.  -0.  -0.   1.8  0.   0.  -0.  -0.  -1.6 -1.1 -0.   0.\n",
      "  -0.   1.7  1.7 -0.  -2.  -0.   0.   1.2 -1.7  1.  -0.   0.  -0.   0.\n",
      "  -0.7  0. ]\n",
      " [-0.   0.   0.   0.  -0.   0.   0.   0.   0.   0.   1.   0.   0.   0.\n",
      "  -0.  -0.  -1.1  0.   0.  -0.  -0.   0.   0.   0.   0.  -0.   0.   0.\n",
      "  -1.5 -0. ]\n",
      " [-1.8  0.   0.  -1.2 -0.  -1.3  1.1 -0.6 -0.7 -0.7  0.   0.   0.   0.\n",
      "  -1.8 -0.5 -0.  -1.6  1.1 -2.  -0.6 -0.  -0.  -1.3  1.  -1.  -1.1 -0.8\n",
      "  -1.2 -0.6]\n",
      " [ 0.  -1.5 -0.   0.   0.   0.  -1.5 -2.  -1.6 -0.   0.8  0.  -1.8 -0.\n",
      "  -0.   0.  -1.3  0.  -0.   1.4 -0.   1.8 -0.6 -1.8  0.   0.   0.  -0.\n",
      "   1.7 -0.8]\n",
      " [ 0.   1.9 -0.  -1.1  0.   0.  -1.9  0.9 -0.  -0.   1.1 -0.7 -0.   0.\n",
      "  -0.   1.2 -1.2  0.9 -1.9 -0.6  0.   0.  -0.9  0.8  0.   0.   0.   0.\n",
      "  -1.7 -1.6]\n",
      " [-0.   0.8  0.   0.   0.   0.   0.  -1.8  0.   0.  -0.  -0.   0.   0.\n",
      "   0.   0.  -1.4  0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.   0.  -0.  -0.\n",
      "   1.8  0. ]\n",
      " [ 1.6 -0.6  0.   0.   0.   0.7  0.   0.9  0.   0.  -1.1 -0.6  0.   0.\n",
      "  -0.  -1.7 -1.2 -0.  -0.9 -0.  -0.   2.   0.8 -0.  -0.   0.   0.  -0.\n",
      "   1.4 -0. ]\n",
      " [-0.  -0.9  0.   0.   0.  -0.   0.   0.  -0.   0.  -0.   0.  -0.   0.\n",
      "  -0.  -0.  -1.  -0.   0.  -0.   0.   0.  -0.  -0.   0.   0.   0.  -0.\n",
      "   1.1  0.9]\n",
      " [-0.   0.9  0.  -0.  -0.  -0.  -0.   1.2 -0.  -0.   0.6 -1.7  0.  -0.\n",
      "  -0.   0.  -1.6  0.  -1.3  0.  -0.   0.   0.   0.   0.  -0.  -0.  -0.\n",
      "  -0.   0.9]\n",
      " [ 1.6 -1.6  0.  -0.  -0.  -1.1  1.1 -1.6 -0.   0.  -0.   0.   0.   0.\n",
      "   0.  -0.6 -0.   0.   0.9 -0.  -0.  -0.   0.   1.5 -0.  -0.   0.  -0.\n",
      "  -1.6  0. ]\n",
      " [ 0.   0.   0.  -0.   0.   0.   0.   0.   0.  -0.   0.  -0.  -0.  -0.\n",
      "   0.  -0.   0.   0.   0.   0.   0.   0.  -0.  -0.   0.   0.   0.  -0.\n",
      "   1.2 -0. ]\n",
      " [ 0.  -0.  -0.  -0.  -0.  -1.6  0.  -0.  -0.  -0.   0.9 -0.  -0.  -0.\n",
      "   0.   0.   0.  -0.   0.  -0.   0.   0.   0.  -1.8  0.   0.  -0.   0.\n",
      "   1.8  0. ]\n",
      " [-1.  -0.   0.   0.   0.   1.  -1.6 -1.5 -0.   0.  -1.1  1.6  0.   0.\n",
      "   0.   0.   0.   0.  -0.   1.3  0.  -0.   1.4 -2.   0.   0.   0.   0.\n",
      "   1.8  0.9]\n",
      " [ 0.8 -0.  -0.   1.6  0.  -1.   1.8 -1.3  1.6 -0.   1.8  1.6 -0.   0.\n",
      "  -0.   0.  -0.   1.3  1.5  1.5 -0.  -1.1  0.  -0.   0.  -0.  -0.  -0.\n",
      "  -1.2  1.8]\n",
      " [-0.8 -0.   0.  -1.7  1.1 -1.5  1.8  0.   1.1  0.8 -1.3 -0.   1.  -1.4\n",
      "  -0.   0.   0.   1.4  0.9  1.2 -0.9  1.1  0.  -0.  -0.   0.9 -1.7  0.8\n",
      "   1.5  0. ]\n",
      " [-0.  -2.  -0.  -0.  -0.   1.8 -0.   1.   0.   0.   0.   0.7 -0.  -0.\n",
      "  -0.  -0.  -1.7  0.   0.  -0.   0.   0.   0.  -1.9  0.   0.   0.  -0.\n",
      "   1.4  0. ]\n",
      " [ 0.  -0.   0.   0.   0.   0.   0.   0.   0.  -0.  -0.8  0.  -0.   0.\n",
      "  -0.  -0.   0.   0.  -0.  -0.  -0.  -0.  -0.   0.  -0.   0.  -0.   0.\n",
      "  -1.2  0. ]\n",
      " [ 0.  -1.   0.  -1.1 -0.   1.1 -0.   1.8  1.   0.  -0.  -2.  -1.4 -0.\n",
      "   0.  -1.4 -0.8  0.   1.1  1.7  0.  -0.9  1.3 -1.8  0.   0.   0.   0.\n",
      "  -0.8  0.8]\n",
      " [ 0.  -0.5  0.  -0.   0.  -0.  -0.  -0.   0.   0.  -0.6 -0.   0.   0.\n",
      "   0.   0.  -0.  -0.  -0.   0.   0.  -0.  -0.   0.  -0.   0.   0.  -0.\n",
      "  -1.9  0. ]\n",
      " [ 1.7 -0.   0.  -0.   0.  -1.4  0.5  2.  -0.   0.   0.   1.3  0.  -0.\n",
      "   0.  -1.9 -0.7  0.   0.  -0.  -0.   0.  -0.9 -1.  -0.  -0.  -0.  -0.\n",
      "  -0.  -1. ]\n",
      " [ 0.9  0.7 -0.   1.2  0.   0.  -1.5  0.   1.8 -0.  -1.  -1.  -1.4 -0.8\n",
      "  -0.   1.   0.   0.7 -1.  -1.7  0.   0.  -0.9 -0.7  0.   1.   0.7 -1.7\n",
      "   1.6  0. ]\n",
      " [ 0.   0.8 -0.   0.   0.  -1.6  0.  -1.5 -0.  -0.  -0.   1.2  0.   0.\n",
      "  -0.   1.1  1.8  0.  -0.9  0.   0.  -0.   0.  -1.  -0.   0.  -0.  -0.\n",
      "  -1.8 -0.8]\n",
      " [ 0.  -2.   0.  -0.   0.   1.4 -0.  -0.   1.1  0.  -0.8  0.6 -0.  -0.\n",
      "  -0.  -1.   0.   0.   1.1  0.  -0.  -1.2 -0.   0.   0.   0.  -0.  -0.\n",
      "   1.1 -0. ]\n",
      " [-0.   2.  -0.  -0.   0.  -0.8  0.   0.  -0.  -0.  -0.  -0.   0.   0.\n",
      "  -0.   0.  -1.8  0.  -0.6 -0.   0.  -0.   0.  -0.   0.   0.   0.  -0.\n",
      "   0.7 -0.7]\n",
      " [ 1.5  1.4 -0.   0.  -0.8 -0.   1.3 -0.   1.   0.8 -0.  -0.   2.   0.9\n",
      "   1.   0.7 -1.6 -0.  -0.  -0.9  1.3  1.8  2.  -2.   0.   1.8  1.9 -1.1\n",
      "   1.9 -0.7]\n",
      " [-1.  -1.9 -0.   0.  -1.1  0.   0.  -1.1  1.4  0.9 -1.8 -0.5 -0.8 -1.2\n",
      "  -0.   1.6 -0.  -0.   0.  -1.6  0.   0.  -1.1 -0.  -0.  -0.   0.   0.\n",
      "  -0.8 -0. ]\n",
      " [ 0.   1.2 -0.  -0.   1.8 -1.2  0.   1.1  0.  -0.6  0.5 -0.   0.   0.8\n",
      "  -0.  -0.7 -1.9 -0.   1.   1.9  0.   1.5 -0.8  0.8  0.  -1.8  0.  -0.\n",
      "   0.   1.4]\n",
      " [ 0.8 -0.  -0.   1.2 -0.   0.  -0.9 -0.  -1.1 -0.7  1.5  1.6  0.  -1.\n",
      "  -0.  -0.  -0.7  1.3  1.1 -1.4  0.  -0.9  1.8  1.4 -0.   0.6 -0.6 -0.\n",
      "  -1.  -1.8]\n",
      " [ 0.   0.  -0.   0.  -0.   0.  -0.   0.   0.   0.  -0.   0.  -0.   0.\n",
      "  -0.  -0.   0.  -0.   0.   0.  -0.   0.   0.  -0.  -0.  -0.  -0.   0.\n",
      "   0.   0. ]\n",
      " [-0.  -1.7  0.   0.   0.  -0.  -0.   0.   0.  -0.   0.  -0.   0.   0.\n",
      "  -0.  -0.   0.   0.  -2.  -0.   0.  -0.   0.  -0.  -0.  -0.  -0.   0.\n",
      "  -0.  -0. ]]\n"
     ]
    }
   ],
   "source": [
    "dg = DataGenerator()\n",
    "data,dag = dg.run(30, 100000, 'non-Gaussian', save=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 30)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "i:\\python_project\\dlbn\\venv\\lib\\site-packages\\sklearn\\linear_model\\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "  warnings.warn(\n",
      "i:\\python_project\\dlbn\\venv\\lib\\site-packages\\sklearn\\linear_model\\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "  warnings.warn(\n",
      "i:\\python_project\\dlbn\\venv\\lib\\site-packages\\sklearn\\linear_model\\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "  warnings.warn(\n",
      "i:\\python_project\\dlbn\\venv\\lib\\site-packages\\sklearn\\linear_model\\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "  warnings.warn(\n",
      "i:\\python_project\\dlbn\\venv\\lib\\site-packages\\sklearn\\linear_model\\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "  warnings.warn(\n",
      "i:\\python_project\\dlbn\\venv\\lib\\site-packages\\sklearn\\linear_model\\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "  warnings.warn(\n",
      "i:\\python_project\\dlbn\\venv\\lib\\site-packages\\sklearn\\linear_model\\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "  warnings.warn(\n",
      "i:\\python_project\\dlbn\\venv\\lib\\site-packages\\sklearn\\linear_model\\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "  warnings.warn(\n",
      "i:\\python_project\\dlbn\\venv\\lib\\site-packages\\sklearn\\linear_model\\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "  warnings.warn(\n",
      "i:\\python_project\\dlbn\\venv\\lib\\site-packages\\sklearn\\linear_model\\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "  warnings.warn(\n",
      "i:\\python_project\\dlbn\\venv\\lib\\site-packages\\sklearn\\linear_model\\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "  warnings.warn(\n",
      "i:\\python_project\\dlbn\\venv\\lib\\site-packages\\sklearn\\linear_model\\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "i:\\python_project\\dlbn\\venv\\lib\\site-packages\\sklearn\\linear_model\\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "  warnings.warn(\n",
      "i:\\python_project\\dlbn\\venv\\lib\\site-packages\\sklearn\\linear_model\\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "  warnings.warn(\n",
      "i:\\python_project\\dlbn\\venv\\lib\\site-packages\\sklearn\\linear_model\\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "  warnings.warn(\n",
      "i:\\python_project\\dlbn\\venv\\lib\\site-packages\\sklearn\\linear_model\\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "  warnings.warn(\n",
      "i:\\python_project\\dlbn\\venv\\lib\\site-packages\\sklearn\\linear_model\\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "  warnings.warn(\n",
      "i:\\python_project\\dlbn\\venv\\lib\\site-packages\\sklearn\\linear_model\\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "  warnings.warn(\n",
      "i:\\python_project\\dlbn\\venv\\lib\\site-packages\\sklearn\\linear_model\\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "  warnings.warn(\n",
      "i:\\python_project\\dlbn\\venv\\lib\\site-packages\\sklearn\\linear_model\\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "  warnings.warn(\n",
      "i:\\python_project\\dlbn\\venv\\lib\\site-packages\\sklearn\\linear_model\\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "  warnings.warn(\n",
      "i:\\python_project\\dlbn\\venv\\lib\\site-packages\\sklearn\\linear_model\\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "  warnings.warn(\n",
      "i:\\python_project\\dlbn\\venv\\lib\\site-packages\\sklearn\\linear_model\\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "  warnings.warn(\n",
      "i:\\python_project\\dlbn\\venv\\lib\\site-packages\\sklearn\\linear_model\\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "  warnings.warn(\n",
      "i:\\python_project\\dlbn\\venv\\lib\\site-packages\\sklearn\\linear_model\\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "i:\\python_project\\dlbn\\venv\\lib\\site-packages\\sklearn\\linear_model\\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "  warnings.warn(\n",
      "i:\\python_project\\dlbn\\venv\\lib\\site-packages\\sklearn\\linear_model\\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "  warnings.warn(\n",
      "i:\\python_project\\dlbn\\venv\\lib\\site-packages\\sklearn\\linear_model\\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "  warnings.warn(\n",
      "i:\\python_project\\dlbn\\venv\\lib\\site-packages\\sklearn\\linear_model\\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<lingam.direct_lingam.DirectLiNGAM at 0x142e54cff70>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl = lingam.DirectLiNGAM()\n",
    "dl.fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         2.34517478e+00,  4.08973273e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         2.25868606e+00, -4.80867679e-01, -3.48722172e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  9.99023860e-01,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00, -1.09911769e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00, -1.49747023e+00,  0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00, -7.76486484e-01,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  7.31269812e-01,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00, -3.59945897e-01,  0.00000000e+00,\n",
       "        -2.28249710e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00, -4.37029649e-01,\n",
       "         8.59753151e-01,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         6.28322675e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00, -2.77305672e-01,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        -1.52074470e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  1.96703343e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00, -1.00113909e+00,  0.00000000e+00,\n",
       "         0.00000000e+00, -4.13421463e-01,  0.00000000e+00,\n",
       "        -3.81707720e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "       [ 0.00000000e+00,  7.99897110e-01,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00, -1.79207949e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00, -1.40511769e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  1.73533062e+00,  0.00000000e+00],\n",
       "       [ 1.34286343e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  2.62931593e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         5.51781999e-01,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "       [ 0.00000000e+00, -8.94165077e-01,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00, -9.97388216e-01,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  1.10223210e+00,  8.98621328e-01],\n",
       "       [ 0.00000000e+00,  8.99577559e-01,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  1.19996925e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  5.98502105e-01, -1.70044507e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00, -1.60028006e+00,  0.00000000e+00,\n",
       "        -1.29728194e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  9.01352175e-01],\n",
       "       [ 6.93407538e-01,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         1.50035515e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00, -5.33388647e-01,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  1.20158459e+00,  0.00000000e+00],\n",
       "       [ 0.00000000e+00, -4.41988340e-03,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00, -1.59944533e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  8.98514943e-01,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00, -1.79755055e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  1.78850822e+00,  0.00000000e+00],\n",
       "       [ 0.00000000e+00,  5.03571051e-01,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        -9.17045634e-01,  1.92103822e-01,  0.00000000e+00,\n",
       "         0.00000000e+00, -1.20166204e+00,  2.61921195e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        -1.02408142e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        -2.14982628e-01,  3.71814825e-01,  0.00000000e+00,\n",
       "        -1.27226822e-01,  0.00000000e+00, -2.57793308e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  1.34194267e+00,  1.62452370e-02],\n",
       "       [ 2.59596665e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         5.24883275e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  9.04126493e-01,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        -3.36378514e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00, -1.42626401e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  2.97865428e+00,  0.00000000e+00,\n",
       "         7.71508288e-01,  0.00000000e+00,  0.00000000e+00],\n",
       "       [ 0.00000000e+00, -1.99481046e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  1.78629076e+00,\n",
       "         0.00000000e+00,  9.85424751e-01,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  6.95890374e-01,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00, -1.70693939e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00, -1.90502085e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  1.41408090e+00,  0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00, -7.84509396e-01,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00, -1.21409746e+00,  0.00000000e+00],\n",
       "       [ 0.00000000e+00,  4.84181646e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  2.21767675e+00,\n",
       "         7.79759961e-01,  4.41800339e+00,  2.20514665e+00,\n",
       "         0.00000000e+00, -4.14010604e+00, -1.66903777e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  3.02881656e+00,  0.00000000e+00,\n",
       "        -3.47675610e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00, -1.01206979e-01,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00, -3.89560509e+00,  9.83339249e-01],\n",
       "       [ 0.00000000e+00, -4.94540844e-01,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00, -6.02208049e-01,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  7.06981566e-03,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00, -1.89396317e+00,  0.00000000e+00],\n",
       "       [ 3.94078533e-01,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         5.95664455e-01,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         2.14289171e+00, -2.42249985e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  1.01711945e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  1.54882708e+00,\n",
       "        -1.59240461e-01,  0.00000000e+00,  0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  1.46270903e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         7.57553696e-01,  3.12403741e+00,  0.00000000e+00,\n",
       "         6.96130471e-01,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00, -1.11092338e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00, -2.47296202e+00,  0.00000000e+00],\n",
       "       [ 0.00000000e+00,  3.58781086e-01,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  3.82245838e-01,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        -1.78361800e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "       [ 0.00000000e+00,  2.01634205e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00, -8.00311735e-01,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  1.44556792e-03,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00, -1.80293795e+00,  0.00000000e+00,\n",
       "        -5.78079105e-01,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  7.04914004e-01, -6.89845656e-01],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00, -1.92565961e+00,  2.45435330e+01,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  4.71886343e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00, -1.93253464e+00,\n",
       "         0.00000000e+00, -3.13022431e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  9.19759499e-02,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00, -1.98038382e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  1.33477053e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  6.95854915e-01, -8.86771292e-01,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "       [ 0.00000000e+00, -1.70069616e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00, -3.96799909e-03,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        -2.00213865e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl.adjacency_matrix_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0. ,  1.9, -0. , -0. , -0. ,  1.8,  0. ,  0. , -0. , -0. , -1.6,\n",
       "        -1.1, -0. ,  0. , -0. ,  1.7,  1.7, -0. , -2. , -0. ,  0. ,  1.2,\n",
       "        -1.7,  1. , -0. ,  0. , -0. ,  0. , -0.7,  0. ],\n",
       "       [-0. ,  0. ,  0. ,  0. , -0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  1. ,\n",
       "         0. ,  0. ,  0. , -0. , -0. , -1.1,  0. ,  0. , -0. , -0. ,  0. ,\n",
       "         0. ,  0. ,  0. , -0. ,  0. ,  0. , -1.5, -0. ],\n",
       "       [-1.8,  0. ,  0. , -1.2, -0. , -1.3,  1.1, -0.6, -0.7, -0.7,  0. ,\n",
       "         0. ,  0. ,  0. , -1.8, -0.5, -0. , -1.6,  1.1, -2. , -0.6, -0. ,\n",
       "        -0. , -1.3,  1. , -1. , -1.1, -0.8, -1.2, -0.6],\n",
       "       [ 0. , -1.5, -0. ,  0. ,  0. ,  0. , -1.5, -2. , -1.6, -0. ,  0.8,\n",
       "         0. , -1.8, -0. , -0. ,  0. , -1.3,  0. , -0. ,  1.4, -0. ,  1.8,\n",
       "        -0.6, -1.8,  0. ,  0. ,  0. , -0. ,  1.7, -0.8],\n",
       "       [ 0. ,  1.9, -0. , -1.1,  0. ,  0. , -1.9,  0.9, -0. , -0. ,  1.1,\n",
       "        -0.7, -0. ,  0. , -0. ,  1.2, -1.2,  0.9, -1.9, -0.6,  0. ,  0. ,\n",
       "        -0.9,  0.8,  0. ,  0. ,  0. ,  0. , -1.7, -1.6],\n",
       "       [-0. ,  0.8,  0. ,  0. ,  0. ,  0. ,  0. , -1.8,  0. ,  0. , -0. ,\n",
       "        -0. ,  0. ,  0. ,  0. ,  0. , -1.4,  0. , -0. , -0. , -0. , -0. ,\n",
       "        -0. , -0. , -0. ,  0. , -0. , -0. ,  1.8,  0. ],\n",
       "       [ 1.6, -0.6,  0. ,  0. ,  0. ,  0.7,  0. ,  0.9,  0. ,  0. , -1.1,\n",
       "        -0.6,  0. ,  0. , -0. , -1.7, -1.2, -0. , -0.9, -0. , -0. ,  2. ,\n",
       "         0.8, -0. , -0. ,  0. ,  0. , -0. ,  1.4, -0. ],\n",
       "       [-0. , -0.9,  0. ,  0. ,  0. , -0. ,  0. ,  0. , -0. ,  0. , -0. ,\n",
       "         0. , -0. ,  0. , -0. , -0. , -1. , -0. ,  0. , -0. ,  0. ,  0. ,\n",
       "        -0. , -0. ,  0. ,  0. ,  0. , -0. ,  1.1,  0.9],\n",
       "       [-0. ,  0.9,  0. , -0. , -0. , -0. , -0. ,  1.2, -0. , -0. ,  0.6,\n",
       "        -1.7,  0. , -0. , -0. ,  0. , -1.6,  0. , -1.3,  0. , -0. ,  0. ,\n",
       "         0. ,  0. ,  0. , -0. , -0. , -0. , -0. ,  0.9],\n",
       "       [ 1.6, -1.6,  0. , -0. , -0. , -1.1,  1.1, -1.6, -0. ,  0. , -0. ,\n",
       "         0. ,  0. ,  0. ,  0. , -0.6, -0. ,  0. ,  0.9, -0. , -0. , -0. ,\n",
       "         0. ,  1.5, -0. , -0. ,  0. , -0. , -1.6,  0. ],\n",
       "       [ 0. ,  0. ,  0. , -0. ,  0. ,  0. ,  0. ,  0. ,  0. , -0. ,  0. ,\n",
       "        -0. , -0. , -0. ,  0. , -0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,\n",
       "        -0. , -0. ,  0. ,  0. ,  0. , -0. ,  1.2, -0. ],\n",
       "       [ 0. , -0. , -0. , -0. , -0. , -1.6,  0. , -0. , -0. , -0. ,  0.9,\n",
       "        -0. , -0. , -0. ,  0. ,  0. ,  0. , -0. ,  0. , -0. ,  0. ,  0. ,\n",
       "         0. , -1.8,  0. ,  0. , -0. ,  0. ,  1.8,  0. ],\n",
       "       [-1. , -0. ,  0. ,  0. ,  0. ,  1. , -1.6, -1.5, -0. ,  0. , -1.1,\n",
       "         1.6,  0. ,  0. ,  0. ,  0. ,  0. ,  0. , -0. ,  1.3,  0. , -0. ,\n",
       "         1.4, -2. ,  0. ,  0. ,  0. ,  0. ,  1.8,  0.9],\n",
       "       [ 0.8, -0. , -0. ,  1.6,  0. , -1. ,  1.8, -1.3,  1.6, -0. ,  1.8,\n",
       "         1.6, -0. ,  0. , -0. ,  0. , -0. ,  1.3,  1.5,  1.5, -0. , -1.1,\n",
       "         0. , -0. ,  0. , -0. , -0. , -0. , -1.2,  1.8],\n",
       "       [-0.8, -0. ,  0. , -1.7,  1.1, -1.5,  1.8,  0. ,  1.1,  0.8, -1.3,\n",
       "        -0. ,  1. , -1.4, -0. ,  0. ,  0. ,  1.4,  0.9,  1.2, -0.9,  1.1,\n",
       "         0. , -0. , -0. ,  0.9, -1.7,  0.8,  1.5,  0. ],\n",
       "       [-0. , -2. , -0. , -0. , -0. ,  1.8, -0. ,  1. ,  0. ,  0. ,  0. ,\n",
       "         0.7, -0. , -0. , -0. , -0. , -1.7,  0. ,  0. , -0. ,  0. ,  0. ,\n",
       "         0. , -1.9,  0. ,  0. ,  0. , -0. ,  1.4,  0. ],\n",
       "       [ 0. , -0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. , -0. , -0.8,\n",
       "         0. , -0. ,  0. , -0. , -0. ,  0. ,  0. , -0. , -0. , -0. , -0. ,\n",
       "        -0. ,  0. , -0. ,  0. , -0. ,  0. , -1.2,  0. ],\n",
       "       [ 0. , -1. ,  0. , -1.1, -0. ,  1.1, -0. ,  1.8,  1. ,  0. , -0. ,\n",
       "        -2. , -1.4, -0. ,  0. , -1.4, -0.8,  0. ,  1.1,  1.7,  0. , -0.9,\n",
       "         1.3, -1.8,  0. ,  0. ,  0. ,  0. , -0.8,  0.8],\n",
       "       [ 0. , -0.5,  0. , -0. ,  0. , -0. , -0. , -0. ,  0. ,  0. , -0.6,\n",
       "        -0. ,  0. ,  0. ,  0. ,  0. , -0. , -0. , -0. ,  0. ,  0. , -0. ,\n",
       "        -0. ,  0. , -0. ,  0. ,  0. , -0. , -1.9,  0. ],\n",
       "       [ 1.7, -0. ,  0. , -0. ,  0. , -1.4,  0.5,  2. , -0. ,  0. ,  0. ,\n",
       "         1.3,  0. , -0. ,  0. , -1.9, -0.7,  0. ,  0. , -0. , -0. ,  0. ,\n",
       "        -0.9, -1. , -0. , -0. , -0. , -0. , -0. , -1. ],\n",
       "       [ 0.9,  0.7, -0. ,  1.2,  0. ,  0. , -1.5,  0. ,  1.8, -0. , -1. ,\n",
       "        -1. , -1.4, -0.8, -0. ,  1. ,  0. ,  0.7, -1. , -1.7,  0. ,  0. ,\n",
       "        -0.9, -0.7,  0. ,  1. ,  0.7, -1.7,  1.6,  0. ],\n",
       "       [ 0. ,  0.8, -0. ,  0. ,  0. , -1.6,  0. , -1.5, -0. , -0. , -0. ,\n",
       "         1.2,  0. ,  0. , -0. ,  1.1,  1.8,  0. , -0.9,  0. ,  0. , -0. ,\n",
       "         0. , -1. , -0. ,  0. , -0. , -0. , -1.8, -0.8],\n",
       "       [ 0. , -2. ,  0. , -0. ,  0. ,  1.4, -0. , -0. ,  1.1,  0. , -0.8,\n",
       "         0.6, -0. , -0. , -0. , -1. ,  0. ,  0. ,  1.1,  0. , -0. , -1.2,\n",
       "        -0. ,  0. ,  0. ,  0. , -0. , -0. ,  1.1, -0. ],\n",
       "       [-0. ,  2. , -0. , -0. ,  0. , -0.8,  0. ,  0. , -0. , -0. , -0. ,\n",
       "        -0. ,  0. ,  0. , -0. ,  0. , -1.8,  0. , -0.6, -0. ,  0. , -0. ,\n",
       "         0. , -0. ,  0. ,  0. ,  0. , -0. ,  0.7, -0.7],\n",
       "       [ 1.5,  1.4, -0. ,  0. , -0.8, -0. ,  1.3, -0. ,  1. ,  0.8, -0. ,\n",
       "        -0. ,  2. ,  0.9,  1. ,  0.7, -1.6, -0. , -0. , -0.9,  1.3,  1.8,\n",
       "         2. , -2. ,  0. ,  1.8,  1.9, -1.1,  1.9, -0.7],\n",
       "       [-1. , -1.9, -0. ,  0. , -1.1,  0. ,  0. , -1.1,  1.4,  0.9, -1.8,\n",
       "        -0.5, -0.8, -1.2, -0. ,  1.6, -0. , -0. ,  0. , -1.6,  0. ,  0. ,\n",
       "        -1.1, -0. , -0. , -0. ,  0. ,  0. , -0.8, -0. ],\n",
       "       [ 0. ,  1.2, -0. , -0. ,  1.8, -1.2,  0. ,  1.1,  0. , -0.6,  0.5,\n",
       "        -0. ,  0. ,  0.8, -0. , -0.7, -1.9, -0. ,  1. ,  1.9,  0. ,  1.5,\n",
       "        -0.8,  0.8,  0. , -1.8,  0. , -0. ,  0. ,  1.4],\n",
       "       [ 0.8, -0. , -0. ,  1.2, -0. ,  0. , -0.9, -0. , -1.1, -0.7,  1.5,\n",
       "         1.6,  0. , -1. , -0. , -0. , -0.7,  1.3,  1.1, -1.4,  0. , -0.9,\n",
       "         1.8,  1.4, -0. ,  0.6, -0.6, -0. , -1. , -1.8],\n",
       "       [ 0. ,  0. , -0. ,  0. , -0. ,  0. , -0. ,  0. ,  0. ,  0. , -0. ,\n",
       "         0. , -0. ,  0. , -0. , -0. ,  0. , -0. ,  0. ,  0. , -0. ,  0. ,\n",
       "         0. , -0. , -0. , -0. , -0. ,  0. ,  0. ,  0. ],\n",
       "       [-0. , -1.7,  0. ,  0. ,  0. , -0. , -0. ,  0. ,  0. , -0. ,  0. ,\n",
       "        -0. ,  0. ,  0. , -0. , -0. ,  0. ,  0. , -2. , -0. ,  0. , -0. ,\n",
       "         0. , -0. , -0. , -0. , -0. ,  0. , -0. , -0. ]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "379.9250232553941"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.abs(dag-dl.adjacency_matrix_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-54.38428289381551"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(dag-dl.adjacency_matrix_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}